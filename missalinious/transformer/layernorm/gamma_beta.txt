Great choice ‚Äî Œ≥ / Œ≤ support is mandatory for a production Transformer.

Below is a BIT-ACCURATE fixed-point LayerNorm with GAMMA & BETA, fully compatible with the fused Attention + Softmax + LayerNorm pipeline you already have.

This is exactly how real accelerators implement LayerNorm.

üìê Fixed-Point Formats (CONSISTENT)
Signal	Format
Input x	Q8.8 (16-bit signed)
Mean	Q8.8
Variance	Q16.16
inv_std	Q0.16
Œ≥ (gamma)	Q8.8
Œ≤ (beta)	Q8.8
Output y	Q8.8

Formula:

y = ((x ‚àí mean) * inv_std) * Œ≥ + Œ≤
